/**
 * Tests for AIPromptGenerator abstract base class
 *
 * Test coverage:
 * - Constructor dependency injection with apiKeys
 * - validate() checks prompt files exist
 * - generate() full workflow with template variables and personality
 * - generate() provider failover logic
 * - Error handling for missing prompts and provider failures
 * - Template variable building with date/time
 * - User prompt formatting with personality
 * - Provider selection and API key handling
 */

import { AIPromptGenerator } from '@/content/generators/ai-prompt-generator';
import { PromptLoader } from '@/content/prompt-loader';
import { ModelTierSelector, type ModelSelection } from '@/api/ai/model-tier-selector';
import type { GenerationContext, GeneratorFormatOptions } from '@/types/content-generator';
import { ModelTier } from '@/types/content-generator';
import { createMockAIProvider, createRateLimitedProvider } from '@tests/__helpers__/mockAIProvider';
import type { PersonalityDimensions } from '@/content/personality';
import { DimensionSubstitutor } from '@/content/dimension-substitutor';

// Mock createAIProvider function
jest.mock('@/api/ai/index.js', () => ({
  createAIProvider: jest.fn((provider: string, apiKey: string, model: string) => {
    return createMockAIProvider({
      response: {
        text: `Generated by ${provider} with ${model}`,
        model: model,
      },
    });
  }),
  AIProviderType: {
    OPENAI: 'openai',
    ANTHROPIC: 'anthropic',
  },
}));

// Mock personality generation
jest.mock('@/content/personality/index.js', () => ({
  generatePersonalityDimensions: jest.fn(() => ({
    mood: 'cheerful',
    energyLevel: 'high',
    humorStyle: 'witty',
    obsession: 'coffee',
  })),
}));

import { createAIProvider } from '@/api/ai/index.js';
import { generatePersonalityDimensions } from '@/content/personality/index.js';

// Concrete test implementation that extends the REAL AIPromptGenerator
class TestAIPromptGenerator extends AIPromptGenerator {
  protected getSystemPromptFile(): string {
    return 'test-system.txt';
  }

  protected getUserPromptFile(): string {
    return 'test-user.txt';
  }
}

// Test implementation with format options support
class TestAIPromptGeneratorWithFormatOptions extends AIPromptGenerator {
  private customFormatOptions?: GeneratorFormatOptions;

  constructor(
    promptLoader: PromptLoader,
    modelTierSelector: ModelTierSelector,
    modelTier: ModelTier,
    apiKeys: Record<string, string> = {},
    formatOptions?: GeneratorFormatOptions
  ) {
    super(promptLoader, modelTierSelector, modelTier, apiKeys, formatOptions);
    this.customFormatOptions = formatOptions;
  }

  protected getSystemPromptFile(): string {
    return 'test-system.txt';
  }

  protected getUserPromptFile(): string {
    return 'test-user.txt';
  }

  // Expose format options for testing
  getFormatOptions(): GeneratorFormatOptions | undefined {
    return this.customFormatOptions;
  }
}

describe('AIPromptGenerator', () => {
  let mockPromptLoader: jest.Mocked<PromptLoader>;
  let mockModelTierSelector: jest.Mocked<ModelTierSelector>;
  const mockApiKeys = {
    openai: 'sk-test-openai-key',
    anthropic: 'sk-ant-test-key',
  };

  beforeEach(() => {
    jest.clearAllMocks();

    mockPromptLoader = {
      loadPrompt: jest.fn(),
      loadPromptWithVariables: jest.fn(),
    } as unknown as jest.Mocked<PromptLoader>;

    mockModelTierSelector = {
      select: jest.fn(),
      getAlternate: jest.fn(),
    } as unknown as jest.Mocked<ModelTierSelector>;
  });

  describe('constructor', () => {
    it('should accept dependencies via dependency injection', () => {
      const generator = new TestAIPromptGenerator(
        mockPromptLoader,
        mockModelTierSelector,
        ModelTier.MEDIUM,
        mockApiKeys
      );

      expect(generator).toBeDefined();
      expect(generator['promptLoader']).toBe(mockPromptLoader);
      expect(generator['modelTierSelector']).toBe(mockModelTierSelector);
      expect(generator['modelTier']).toBe(ModelTier.MEDIUM);
      expect(generator['apiKeys']).toBe(mockApiKeys);
    });

    it('should support all model tiers', () => {
      const lightGen = new TestAIPromptGenerator(
        mockPromptLoader,
        mockModelTierSelector,
        ModelTier.LIGHT,
        mockApiKeys
      );
      const mediumGen = new TestAIPromptGenerator(
        mockPromptLoader,
        mockModelTierSelector,
        ModelTier.MEDIUM,
        mockApiKeys
      );
      const heavyGen = new TestAIPromptGenerator(
        mockPromptLoader,
        mockModelTierSelector,
        ModelTier.HEAVY,
        mockApiKeys
      );

      expect(lightGen['modelTier']).toBe(ModelTier.LIGHT);
      expect(mediumGen['modelTier']).toBe(ModelTier.MEDIUM);
      expect(heavyGen['modelTier']).toBe(ModelTier.HEAVY);
    });

    it('should allow empty apiKeys as default', () => {
      const generator = new TestAIPromptGenerator(
        mockPromptLoader,
        mockModelTierSelector,
        ModelTier.MEDIUM
      );

      expect(generator['apiKeys']).toEqual({});
    });
  });

  describe('validate()', () => {
    it('should return valid when both prompt files exist', async () => {
      mockPromptLoader.loadPrompt.mockResolvedValue('prompt content');

      const generator = new TestAIPromptGenerator(
        mockPromptLoader,
        mockModelTierSelector,
        ModelTier.MEDIUM,
        mockApiKeys
      );

      const result = await generator.validate();

      expect(result.valid).toBe(true);
      expect(result.errors).toBeUndefined();
      expect(mockPromptLoader.loadPrompt).toHaveBeenCalledWith('system', 'test-system.txt');
      expect(mockPromptLoader.loadPrompt).toHaveBeenCalledWith('user', 'test-user.txt');
    });

    it('should return invalid when system prompt is missing', async () => {
      mockPromptLoader.loadPrompt
        .mockRejectedValueOnce(new Error('System prompt not found'))
        .mockResolvedValueOnce('user prompt');

      const generator = new TestAIPromptGenerator(
        mockPromptLoader,
        mockModelTierSelector,
        ModelTier.MEDIUM,
        mockApiKeys
      );

      const result = await generator.validate();

      expect(result.valid).toBe(false);
      expect(result.errors).toHaveLength(1);
      expect(result.errors?.[0]).toContain('System prompt not found');
      expect(result.errors?.[0]).toContain('prompts/system/test-system.txt');
    });

    it('should return invalid when user prompt is missing', async () => {
      mockPromptLoader.loadPrompt
        .mockResolvedValueOnce('system prompt')
        .mockRejectedValueOnce(new Error('User prompt not found'));

      const generator = new TestAIPromptGenerator(
        mockPromptLoader,
        mockModelTierSelector,
        ModelTier.MEDIUM,
        mockApiKeys
      );

      const result = await generator.validate();

      expect(result.valid).toBe(false);
      expect(result.errors).toHaveLength(1);
      expect(result.errors?.[0]).toContain('User prompt not found');
      expect(result.errors?.[0]).toContain('prompts/user/test-user.txt');
    });

    it('should return invalid when both prompts are missing', async () => {
      mockPromptLoader.loadPrompt.mockRejectedValue(new Error('Prompt not found'));

      const generator = new TestAIPromptGenerator(
        mockPromptLoader,
        mockModelTierSelector,
        ModelTier.MEDIUM,
        mockApiKeys
      );

      const result = await generator.validate();

      expect(result.valid).toBe(false);
      expect(result.errors).toHaveLength(2);
      expect(result.errors?.[0]).toContain('System prompt not found');
      expect(result.errors?.[1]).toContain('User prompt not found');
    });
  });

  describe('generate()', () => {
    const mockContext: GenerationContext = {
      updateType: 'major',
      timestamp: new Date('2025-01-15T12:00:00Z'),
    };

    beforeEach(() => {
      mockPromptLoader.loadPromptWithVariables
        .mockResolvedValueOnce('System prompt with variables')
        .mockResolvedValueOnce('User prompt with variables');

      mockModelTierSelector.select.mockReturnValue({
        provider: 'openai',
        model: 'gpt-4o',
      });
    });

    describe('personality handling', () => {
      it('should use provided personality from context', async () => {
        const customPersonality: PersonalityDimensions = {
          mood: 'excited',
          energyLevel: 'medium',
          humorStyle: 'sarcastic',
          obsession: 'testing',
        };

        const contextWithPersonality: GenerationContext = {
          ...mockContext,
          personality: customPersonality,
        };

        const generator = new TestAIPromptGenerator(
          mockPromptLoader,
          mockModelTierSelector,
          ModelTier.MEDIUM,
          mockApiKeys
        );

        const result = await generator.generate(contextWithPersonality);

        expect(generatePersonalityDimensions).not.toHaveBeenCalled();
        expect(result.metadata?.personality).toEqual(customPersonality);
      });

      it('should generate personality when not provided in context', async () => {
        const generator = new TestAIPromptGenerator(
          mockPromptLoader,
          mockModelTierSelector,
          ModelTier.MEDIUM,
          mockApiKeys
        );

        const result = await generator.generate(mockContext);

        expect(generatePersonalityDimensions).toHaveBeenCalled();
        expect(result.metadata?.personality).toEqual({
          mood: 'cheerful',
          energyLevel: 'high',
          humorStyle: 'witty',
          obsession: 'coffee',
        });
      });
    });

    describe('template variables', () => {
      it('should build template variables with personality and date/time', async () => {
        const generator = new TestAIPromptGenerator(
          mockPromptLoader,
          mockModelTierSelector,
          ModelTier.MEDIUM,
          mockApiKeys
        );

        await generator.generate(mockContext);

        expect(mockPromptLoader.loadPromptWithVariables).toHaveBeenCalledWith(
          'system',
          'test-system.txt',
          expect.objectContaining({
            mood: 'cheerful',
            energyLevel: 'high',
            humorStyle: 'witty',
            obsession: 'coffee',
            date: expect.stringContaining('2025'),
            time: expect.any(String),
            persona: 'Houseboy',
          })
        );
      });

      it('should format date and time correctly', async () => {
        const generator = new TestAIPromptGenerator(
          mockPromptLoader,
          mockModelTierSelector,
          ModelTier.MEDIUM,
          mockApiKeys
        );

        await generator.generate(mockContext);

        const call = mockPromptLoader.loadPromptWithVariables.mock.calls[0];
        const templateVars = call[2];

        expect(templateVars.date).toMatch(/\w+, \w+ \d+, \d{4}/);
        expect(templateVars.time).toMatch(/\d+:\d{2}/);
      });
    });

    describe('prompt formatting', () => {
      it('should load prompts with template variables', async () => {
        const generator = new TestAIPromptGenerator(
          mockPromptLoader,
          mockModelTierSelector,
          ModelTier.MEDIUM,
          mockApiKeys
        );

        await generator.generate(mockContext);

        expect(mockPromptLoader.loadPromptWithVariables).toHaveBeenCalledWith(
          'system',
          'test-system.txt',
          expect.any(Object)
        );
        expect(mockPromptLoader.loadPromptWithVariables).toHaveBeenCalledWith(
          'user',
          'test-user.txt',
          expect.any(Object)
        );
      });

      it('should format user prompt with context', async () => {
        const generator = new TestAIPromptGenerator(
          mockPromptLoader,
          mockModelTierSelector,
          ModelTier.MEDIUM,
          mockApiKeys
        );

        const result = await generator.generate(mockContext);

        const formattedPrompt = result.metadata?.userPrompt || '';
        expect(formattedPrompt).toContain('CURRENT CONTEXT:');
        expect(formattedPrompt).toContain('Date:');
        expect(formattedPrompt).toContain('Time:');
        expect(formattedPrompt).toContain('Update Type: major');
        expect(formattedPrompt).toContain('PERSONALITY FOR THIS RESPONSE:');
        expect(formattedPrompt).toContain('Mood: cheerful');
        expect(formattedPrompt).toContain('Energy: high');
        expect(formattedPrompt).toContain('Humor Style: witty');
        expect(formattedPrompt).toContain('Current Obsession: coffee');
      });

      it('should include base prompt before context', async () => {
        // Reset mocks and set up fresh ones
        mockPromptLoader.loadPromptWithVariables.mockReset();
        mockPromptLoader.loadPromptWithVariables
          .mockResolvedValueOnce('System prompt')
          .mockResolvedValueOnce('Generate motivational content');

        const generator = new TestAIPromptGenerator(
          mockPromptLoader,
          mockModelTierSelector,
          ModelTier.MEDIUM,
          mockApiKeys
        );

        const result = await generator.generate(mockContext);

        const formattedPrompt = result.metadata?.userPrompt || '';
        expect(formattedPrompt).toMatch(/^Generate motivational content/);
      });
    });

    describe('provider selection', () => {
      it('should select model using ModelTierSelector', async () => {
        const generator = new TestAIPromptGenerator(
          mockPromptLoader,
          mockModelTierSelector,
          ModelTier.HEAVY,
          mockApiKeys
        );

        await generator.generate(mockContext);

        expect(mockModelTierSelector.select).toHaveBeenCalledWith(ModelTier.HEAVY);
      });

      it('should create provider with correct parameters', async () => {
        mockModelTierSelector.select.mockReturnValue({
          provider: 'anthropic',
          model: 'claude-3-5-sonnet-20241022',
        });

        const generator = new TestAIPromptGenerator(
          mockPromptLoader,
          mockModelTierSelector,
          ModelTier.MEDIUM,
          mockApiKeys
        );

        await generator.generate(mockContext);

        expect(createAIProvider).toHaveBeenCalledWith(
          'anthropic',
          'sk-ant-test-key',
          'claude-3-5-sonnet-20241022'
        );
      });

      it('should throw error when API key not found', async () => {
        mockModelTierSelector.select.mockReturnValue({
          provider: 'unknown-provider',
          model: 'some-model',
        });

        const generator = new TestAIPromptGenerator(
          mockPromptLoader,
          mockModelTierSelector,
          ModelTier.MEDIUM,
          mockApiKeys
        );

        await expect(generator.generate(mockContext)).rejects.toThrow(
          'API key not found for provider: unknown-provider'
        );
      });

      it('should generate successfully with primary provider', async () => {
        const generatedText = 'Motivational quote here';
        (createAIProvider as jest.Mock).mockReturnValue(
          createMockAIProvider({
            response: {
              text: generatedText,
              model: 'gpt-4o',
              tokensUsed: 150,
            },
          })
        );

        const generator = new TestAIPromptGenerator(
          mockPromptLoader,
          mockModelTierSelector,
          ModelTier.MEDIUM,
          mockApiKeys
        );

        const result = await generator.generate(mockContext);

        expect(result.text).toBe(generatedText);
        expect(result.outputMode).toBe('text');
        expect(result.metadata?.model).toBe('gpt-4o');
        expect(result.metadata?.tier).toBe(ModelTier.MEDIUM);
        expect(result.metadata?.provider).toBe('openai');
        expect(result.metadata?.tokensUsed).toBe(150);
        expect(result.metadata?.failedOver).toBeUndefined();
      });

      it('should include prompts and personality in metadata', async () => {
        // Reset mocks and set up fresh ones
        mockPromptLoader.loadPromptWithVariables.mockReset();
        mockPromptLoader.loadPromptWithVariables
          .mockResolvedValueOnce('System: Be helpful')
          .mockResolvedValueOnce('User: Generate quote');

        const generator = new TestAIPromptGenerator(
          mockPromptLoader,
          mockModelTierSelector,
          ModelTier.MEDIUM,
          mockApiKeys
        );

        const result = await generator.generate(mockContext);

        expect(result.metadata?.systemPrompt).toBe('System: Be helpful');
        expect(result.metadata?.userPrompt).toContain('User: Generate quote');
        expect(result.metadata?.personality).toEqual({
          mood: 'cheerful',
          energyLevel: 'high',
          humorStyle: 'witty',
          obsession: 'coffee',
        });
      });
    });

    describe('provider failover', () => {
      it('should failover to alternate when primary fails', async () => {
        const primarySelection: ModelSelection = {
          provider: 'openai',
          model: 'gpt-4o',
        };
        const alternateSelection: ModelSelection = {
          provider: 'anthropic',
          model: 'claude-sonnet',
        };

        mockModelTierSelector.select.mockReturnValue(primarySelection);
        mockModelTierSelector.getAlternate.mockReturnValue(alternateSelection);

        (createAIProvider as jest.Mock)
          .mockReturnValueOnce(createRateLimitedProvider('openai'))
          .mockReturnValueOnce(
            createMockAIProvider({
              response: {
                text: 'Alternate provider response',
                model: 'claude-sonnet',
              },
            })
          );

        const generator = new TestAIPromptGenerator(
          mockPromptLoader,
          mockModelTierSelector,
          ModelTier.MEDIUM,
          mockApiKeys
        );

        const result = await generator.generate(mockContext);

        expect(result.text).toBe('Alternate provider response');
        expect(result.metadata?.provider).toBe('anthropic');
        expect(result.metadata?.model).toBe('claude-sonnet');
        expect(result.metadata?.failedOver).toBe(true);
        expect(result.metadata?.primaryError).toContain('Rate limit exceeded');
      });

      it('should include primary error in metadata after failover', async () => {
        const primarySelection: ModelSelection = {
          provider: 'openai',
          model: 'gpt-4o',
        };
        const alternateSelection: ModelSelection = {
          provider: 'anthropic',
          model: 'claude-opus',
        };

        mockModelTierSelector.select.mockReturnValue(primarySelection);
        mockModelTierSelector.getAlternate.mockReturnValue(alternateSelection);

        const primaryError = new Error('Primary failed: Rate limit');
        (createAIProvider as jest.Mock)
          .mockReturnValueOnce(
            createMockAIProvider({
              shouldFail: true,
              failureError: primaryError,
            })
          )
          .mockReturnValueOnce(
            createMockAIProvider({
              response: { text: 'Success', model: 'claude-opus' },
            })
          );

        const generator = new TestAIPromptGenerator(
          mockPromptLoader,
          mockModelTierSelector,
          ModelTier.MEDIUM,
          mockApiKeys
        );

        const result = await generator.generate(mockContext);

        expect(result.metadata?.failedOver).toBe(true);
        expect(result.metadata?.primaryError).toContain('Primary failed');
      });

      it('should throw when all providers fail', async () => {
        const primarySelection: ModelSelection = {
          provider: 'openai',
          model: 'gpt-4o',
        };
        const alternateSelection: ModelSelection = {
          provider: 'anthropic',
          model: 'claude-opus',
        };

        mockModelTierSelector.select.mockReturnValue(primarySelection);
        mockModelTierSelector.getAlternate.mockReturnValue(alternateSelection);

        (createAIProvider as jest.Mock)
          .mockReturnValueOnce(createRateLimitedProvider('openai'))
          .mockReturnValueOnce(
            createMockAIProvider({
              shouldFail: true,
              failureError: new Error('Alternate also failed'),
            })
          );

        const generator = new TestAIPromptGenerator(
          mockPromptLoader,
          mockModelTierSelector,
          ModelTier.MEDIUM,
          mockApiKeys
        );

        await expect(generator.generate(mockContext)).rejects.toThrow(
          /All AI providers failed for tier medium.*Alternate also failed/
        );
      });

      it('should throw when primary fails and no alternate', async () => {
        const primarySelection: ModelSelection = {
          provider: 'openai',
          model: 'gpt-4o',
        };

        mockModelTierSelector.select.mockReturnValue(primarySelection);
        mockModelTierSelector.getAlternate.mockReturnValue(null);

        (createAIProvider as jest.Mock).mockReturnValue(createRateLimitedProvider('openai'));

        const generator = new TestAIPromptGenerator(
          mockPromptLoader,
          mockModelTierSelector,
          ModelTier.MEDIUM,
          mockApiKeys
        );

        await expect(generator.generate(mockContext)).rejects.toThrow(
          /All AI providers failed for tier medium.*Rate limit exceeded/
        );

        expect(mockModelTierSelector.getAlternate).toHaveBeenCalledWith(primarySelection);
      });

      it('should preserve tier after failover', async () => {
        const primarySelection: ModelSelection = {
          provider: 'openai',
          model: 'gpt-4o',
        };
        const alternateSelection: ModelSelection = {
          provider: 'anthropic',
          model: 'claude-sonnet',
        };

        mockModelTierSelector.select.mockReturnValue(primarySelection);
        mockModelTierSelector.getAlternate.mockReturnValue(alternateSelection);

        (createAIProvider as jest.Mock)
          .mockReturnValueOnce(createRateLimitedProvider('openai'))
          .mockReturnValueOnce(
            createMockAIProvider({
              response: { text: 'Success', model: 'claude-sonnet' },
            })
          );

        const generator = new TestAIPromptGenerator(
          mockPromptLoader,
          mockModelTierSelector,
          ModelTier.HEAVY,
          mockApiKeys
        );

        const result = await generator.generate(mockContext);

        expect(result.metadata?.tier).toBe(ModelTier.HEAVY);
      });
    });

    describe('edge cases', () => {
      it('should handle minimal context', async () => {
        // Reset module mocks
        mockPromptLoader.loadPromptWithVariables.mockReset();
        mockPromptLoader.loadPromptWithVariables
          .mockResolvedValueOnce('System prompt')
          .mockResolvedValueOnce('User prompt');

        // Reset createAIProvider mock
        (createAIProvider as jest.Mock).mockReturnValue(
          createMockAIProvider({
            response: {
              text: 'Generated content',
              model: 'gpt-4o',
            },
          })
        );

        const minimalContext: GenerationContext = {
          updateType: 'minor',
          timestamp: new Date('2025-01-15T12:00:00Z'),
        };

        const generator = new TestAIPromptGenerator(
          mockPromptLoader,
          mockModelTierSelector,
          ModelTier.MEDIUM,
          mockApiKeys
        );

        const result = await generator.generate(minimalContext);

        expect(result).toBeDefined();
        expect(result.metadata?.userPrompt).toContain('Update Type: minor');
      });

      it('should handle different update types', async () => {
        // Reset module mocks
        mockPromptLoader.loadPromptWithVariables.mockReset();
        mockPromptLoader.loadPromptWithVariables.mockResolvedValue('Test prompt');

        // Reset createAIProvider mock
        (createAIProvider as jest.Mock).mockReturnValue(
          createMockAIProvider({
            response: {
              text: 'Generated content',
              model: 'gpt-4o',
            },
          })
        );

        const generator = new TestAIPromptGenerator(
          mockPromptLoader,
          mockModelTierSelector,
          ModelTier.MEDIUM,
          mockApiKeys
        );

        const majorResult = await generator.generate({
          updateType: 'major',
          timestamp: new Date(),
        });
        const minorResult = await generator.generate({
          updateType: 'minor',
          timestamp: new Date(),
        });

        expect(majorResult.metadata?.userPrompt).toContain('Update Type: major');
        expect(minorResult.metadata?.userPrompt).toContain('Update Type: minor');
      });

      it('should work with all model tiers', async () => {
        // Reset module mocks
        mockPromptLoader.loadPromptWithVariables.mockReset();
        mockPromptLoader.loadPromptWithVariables.mockResolvedValue('Test prompt');

        // Reset createAIProvider mock
        (createAIProvider as jest.Mock).mockReturnValue(
          createMockAIProvider({
            response: {
              text: 'Generated content',
              model: 'gpt-4o',
            },
          })
        );

        const lightGen = new TestAIPromptGenerator(
          mockPromptLoader,
          mockModelTierSelector,
          ModelTier.LIGHT,
          mockApiKeys
        );
        const mediumGen = new TestAIPromptGenerator(
          mockPromptLoader,
          mockModelTierSelector,
          ModelTier.MEDIUM,
          mockApiKeys
        );
        const heavyGen = new TestAIPromptGenerator(
          mockPromptLoader,
          mockModelTierSelector,
          ModelTier.HEAVY,
          mockApiKeys
        );

        const lightResult = await lightGen.generate(mockContext);
        const mediumResult = await mediumGen.generate(mockContext);
        const heavyResult = await heavyGen.generate(mockContext);

        expect(lightResult.metadata?.tier).toBe(ModelTier.LIGHT);
        expect(mediumResult.metadata?.tier).toBe(ModelTier.MEDIUM);
        expect(heavyResult.metadata?.tier).toBe(ModelTier.HEAVY);

        expect(mockModelTierSelector.select).toHaveBeenCalledWith(ModelTier.LIGHT);
        expect(mockModelTierSelector.select).toHaveBeenCalledWith(ModelTier.MEDIUM);
        expect(mockModelTierSelector.select).toHaveBeenCalledWith(ModelTier.HEAVY);
      });
    });
  });

  describe('format options integration', () => {
    const mockContext: GenerationContext = {
      updateType: 'major',
      timestamp: new Date('2025-01-15T12:00:00Z'),
    };

    beforeEach(() => {
      mockPromptLoader.loadPromptWithVariables.mockReset();
      mockModelTierSelector.select.mockReturnValue({
        provider: 'openai',
        model: 'gpt-4o',
      });

      // Reset createAIProvider mock
      (createAIProvider as jest.Mock).mockReturnValue(
        createMockAIProvider({
          response: {
            text: 'Generated content',
            model: 'gpt-4o',
          },
        })
      );
    });

    describe('constructor with format options', () => {
      it('should accept format options as optional parameter', () => {
        const formatOptions: GeneratorFormatOptions = {
          maxLines: 3,
          maxCharsPerLine: 18,
        };

        const generator = new TestAIPromptGeneratorWithFormatOptions(
          mockPromptLoader,
          mockModelTierSelector,
          ModelTier.MEDIUM,
          mockApiKeys,
          formatOptions
        );

        expect(generator).toBeDefined();
        expect(generator.getFormatOptions()).toEqual(formatOptions);
      });

      it('should work without format options (backwards compatibility)', () => {
        const generator = new TestAIPromptGenerator(
          mockPromptLoader,
          mockModelTierSelector,
          ModelTier.MEDIUM,
          mockApiKeys
        );

        expect(generator).toBeDefined();
      });
    });

    describe('dimension substitution in prompts', () => {
      it('should substitute {{maxChars}} and {{maxLines}} with defaults when no format options', async () => {
        // Setup prompt that contains dimension placeholders
        mockPromptLoader.loadPromptWithVariables
          .mockResolvedValueOnce('System: Max {{maxChars}} chars, {{maxLines}} lines')
          .mockResolvedValueOnce('User prompt');

        const generator = new TestAIPromptGenerator(
          mockPromptLoader,
          mockModelTierSelector,
          ModelTier.MEDIUM,
          mockApiKeys
        );

        const result = await generator.generate(mockContext);

        // DimensionSubstitutor should have been applied with defaults (21 chars, 5 lines)
        // The system prompt should have dimension variables substituted
        expect(result.metadata?.systemPrompt).toBe('System: Max 21 chars, 5 lines');
      });

      it('should substitute {{maxChars}} with custom value from format options', async () => {
        const formatOptions: GeneratorFormatOptions = {
          maxCharsPerLine: 15,
        };

        mockPromptLoader.loadPromptWithVariables
          .mockResolvedValueOnce('Max {{maxChars}} characters per line')
          .mockResolvedValueOnce('User prompt');

        const generator = new TestAIPromptGeneratorWithFormatOptions(
          mockPromptLoader,
          mockModelTierSelector,
          ModelTier.MEDIUM,
          mockApiKeys,
          formatOptions
        );

        const result = await generator.generate(mockContext);

        // Should use custom maxChars (15) and default maxLines (5)
        expect(result.metadata?.systemPrompt).toBe('Max 15 characters per line');
      });

      it('should substitute {{maxLines}} with custom value from format options', async () => {
        const formatOptions: GeneratorFormatOptions = {
          maxLines: 3,
        };

        mockPromptLoader.loadPromptWithVariables
          .mockResolvedValueOnce('Use {{maxLines}} lines maximum')
          .mockResolvedValueOnce('User prompt');

        const generator = new TestAIPromptGeneratorWithFormatOptions(
          mockPromptLoader,
          mockModelTierSelector,
          ModelTier.MEDIUM,
          mockApiKeys,
          formatOptions
        );

        const result = await generator.generate(mockContext);

        // Should use default maxChars (21) and custom maxLines (3)
        expect(result.metadata?.systemPrompt).toBe('Use 3 lines maximum');
      });

      it('should substitute both {{maxChars}} and {{maxLines}} with custom values', async () => {
        const formatOptions: GeneratorFormatOptions = {
          maxCharsPerLine: 18,
          maxLines: 4,
        };

        mockPromptLoader.loadPromptWithVariables
          .mockResolvedValueOnce('{{maxChars}} chars, {{maxLines}} lines')
          .mockResolvedValueOnce('User prompt');

        const generator = new TestAIPromptGeneratorWithFormatOptions(
          mockPromptLoader,
          mockModelTierSelector,
          ModelTier.MEDIUM,
          mockApiKeys,
          formatOptions
        );

        const result = await generator.generate(mockContext);

        expect(result.metadata?.systemPrompt).toBe('18 chars, 4 lines');
      });

      it('should preserve other template variables while substituting dimensions', async () => {
        const formatOptions: GeneratorFormatOptions = {
          maxCharsPerLine: 20,
        };

        // The prompt loader returns the result after personality substitution
        // but dimension variables should still be present and need substitution
        mockPromptLoader.loadPromptWithVariables
          .mockResolvedValueOnce('Mood: cheerful, Max: {{maxChars}} chars')
          .mockResolvedValueOnce('User prompt');

        const generator = new TestAIPromptGeneratorWithFormatOptions(
          mockPromptLoader,
          mockModelTierSelector,
          ModelTier.MEDIUM,
          mockApiKeys,
          formatOptions
        );

        const result = await generator.generate(mockContext);

        // Dimensions should be substituted, personality should remain as-is
        // (personality is already substituted by loadPromptWithVariables)
        expect(result.metadata?.systemPrompt).toBe('Mood: cheerful, Max: 20 chars');
      });
    });

    describe('format options in metadata', () => {
      it('should include format options in generation metadata', async () => {
        const formatOptions: GeneratorFormatOptions = {
          maxCharsPerLine: 18,
          maxLines: 4,
          textAlign: 'center',
        };

        mockPromptLoader.loadPromptWithVariables
          .mockResolvedValueOnce('System prompt')
          .mockResolvedValueOnce('User prompt');

        const generator = new TestAIPromptGeneratorWithFormatOptions(
          mockPromptLoader,
          mockModelTierSelector,
          ModelTier.MEDIUM,
          mockApiKeys,
          formatOptions
        );

        const result = await generator.generate(mockContext);

        expect(result.metadata?.formatOptions).toEqual(formatOptions);
      });

      it('should not include formatOptions in metadata when not provided', async () => {
        mockPromptLoader.loadPromptWithVariables
          .mockResolvedValueOnce('System prompt')
          .mockResolvedValueOnce('User prompt');

        const generator = new TestAIPromptGenerator(
          mockPromptLoader,
          mockModelTierSelector,
          ModelTier.MEDIUM,
          mockApiKeys
        );

        const result = await generator.generate(mockContext);

        expect(result.metadata?.formatOptions).toBeUndefined();
      });
    });

    describe('DimensionSubstitutor integration', () => {
      it('should use DimensionSubstitutor for template substitution', async () => {
        // This test verifies the integration with DimensionSubstitutor
        const substitutor = new DimensionSubstitutor();
        const defaults = substitutor.getDefaults();

        mockPromptLoader.loadPromptWithVariables
          .mockResolvedValueOnce('{{maxChars}} chars, {{maxLines}} lines')
          .mockResolvedValueOnce('User prompt');

        const generator = new TestAIPromptGenerator(
          mockPromptLoader,
          mockModelTierSelector,
          ModelTier.MEDIUM,
          mockApiKeys
        );

        const result = await generator.generate(mockContext);

        // Should match the defaults from DimensionSubstitutor
        expect(result.metadata?.systemPrompt).toBe(
          `${defaults.maxChars} chars, ${defaults.maxLines} lines`
        );
      });

      it('should apply dimension substitution after loading prompts', async () => {
        // Verifies the order of operations:
        // 1. Load prompt with personality variables
        // 2. Apply dimension substitution
        const formatOptions: GeneratorFormatOptions = {
          maxCharsPerLine: 16,
          maxLines: 3,
        };

        mockPromptLoader.loadPromptWithVariables
          .mockResolvedValueOnce('LIMIT: {{maxChars}} | LINES: {{maxLines}}')
          .mockResolvedValueOnce('User prompt');

        const generator = new TestAIPromptGeneratorWithFormatOptions(
          mockPromptLoader,
          mockModelTierSelector,
          ModelTier.MEDIUM,
          mockApiKeys,
          formatOptions
        );

        const result = await generator.generate(mockContext);

        expect(result.metadata?.systemPrompt).toBe('LIMIT: 16 | LINES: 3');
      });
    });
  });
});
